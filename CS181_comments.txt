Very math / stat based course. Useful for learning the theory underlying machine learning techniques, but not as practical as most CS concentrators might want.
A very interesting course. I highly recommend having some knowledge of probability/statistics and probably some Python. Practical assignments are quite enjoyable if you start early and get into them. Through lecture, section, and the textbook (I really enjoyed Bishop's Pattern Recognition and Machine Learning) you have the opportunity to pick up a lot of the theory behind machine learning algorithms, but the course emphasizes intuition and practical knowledge of topics, so deep mathematical rigor is not expected on exams, etc.
Machine learning is a very cool and useful subject, and CS181 is a great introduction to the subject. You'll learn a good deal and get hands-on experience with implementations while also chugging through some of the theory. I did not like the readings in the Bishop textbook because they were long, dry, and overly detailed for our purposes, but some of the course note readings were excellent. Lectures, course notes, and assignments worked together well to present the course material.
The only reason you should take this course is to realize that machine learning is not what you think it is - machine learning is basically applied statistics. But this is "applied" in the worst sense - it lacks the intellectual consistency and beauty of Stat 110 but also is not buoyed by the tools of the lower Stat classes. The math is not covered in sufficient detail to make it a good higher-level Stat class, and the coding is abysmal for a class in the CS department. This course sits at the awkward intersection of multiple fields and lacks the best qualities of each of them. If you already know that, you are better off taking online machine learning courses - they present the subject matter in a much better way. The teaching staff, problem sets, and practicals offered by CS181 add very little value to the book - which is bad to begin with. The entire course is practically self-taught. Stay away from this course, unless you want to end any delusions you may have about machine learning.
The class was pretty poorly managed around the middle, though this really dramatically improved in the final third of the course. Also we never really get very deep into anything, so you end up with pretty minimal insight and intuition beyond what we are explicitly told as a rule of thumb. It's also a little annoying when the lesson on every practical is not "be clever with your methods" but "be clever with your features." Many problems we'd bring these tools to bear on won't have the option for getting better or smarter features.
Even though this class won't teach you how to make your own Siri, 181 is still a really cool class. You'll learn how a lot of methods in real-life machine learning work, and some of its results are surprising (or surprisingly nice). Although you can get away with not putting in too much work on Practicals, it's really fun to see how well you can do (especially because there is a competitive component via Kaggle to it). That being said, the baseline feels like it could be raised, but nonetheless it is a fun class to take.
Start your homework/practicals early, you will never know how much time, it will take you to have ready a code and to obtain the correct results.
Very very interesting topic. Machine learning is awesome. I liked this course despite the fact that the structure, teaching, and psets were subpar. Finale's new so I guess this is to be expected. Practicals were a lot of fun.
Don't feel like I learned as much machine learning as I would have liked. Finale is a decent lecturer but can be disorganized at times. They definitely need to be better about having accessible resources/notes/solutions in the future.
It's a good introduction to Machine Learning, but some of the assignments (the Practicals) are quite annoying and don't teach anything. I'd take this course again if I went back in time, but sometimes it's a bit frustrating.
Great intro to ML, this is a class that will teach you a lot and give you a good look at what both the theory and the application of ML is. Be prepared for a good amount of work, and definitely take Stat 110 before this!
This course pretends to have a strong support system for people with less background, but it doesn't become apparent that it's nonexistent until around the add/drop deadline. As a result, students without the recommended math background are encouraged early on to take a class that they're not prepared for, setting them up for failure. Do not take this class unless you have excellent statistics, matrix calculus, and programming skills.
If you are interested in the topic and like classes that actually challenge you, take this class
This is a great class that introduces many cool concepts in machine learning! Unfortunately, there aren't a lot of supplementary notes and the book is too dense to actually read, so unless you're very comfortable with statistics and math, most of the explanations will not make a lot of sense. Although I have a vague sense of when to use the different machine learning methods, everything still feels pretty black box. This class also suffers from notational problems, where the lecturer will write different notations and you'll be throughly confused about what's going on. Psets will take a good chunk of time to understand what it's asking and to implement the actual problem (~10 hours), so plan accordingly. Grade-wise, it's pretty easy to get good scores on homework/practicals, but midterm grades are pretty bad across the board... but no final/final project!
Start early for practicals!
This class was miserable. The staff support was nonexistent, and it was very different from other CS classes in which they expected you to meet in person with the TF or instructor to go over anything, which is unrealistic when they hold only one office hour slot at night covered by 2 TFs when there are so many students in the class. The content was fine and lectures are pretty good, but the support was definitely not there.
You need to know linear algebra and vector calculus
This class is awesome, but be prepared to work hard
Have a solid background in linear algebra and probability.
I do not recommend this course if you do not meet the requirements (probability, statistical inference, linear algebra, and coding). The lectures were interesting and well taught, but the homework is very demanding and time consuming. I did not feel prepared for the first exam despite studying, since the exam was different to what we had done in class, section, and homework. The sections may be helpful depending on the TFs, and the quality of TFs is very variable. Overall this was an interesting but very stressful course.
fine class
Bad class, bad teaching. Not particularly hard although takes a lot of time, but rather very confusing and you won't find a lot of immediate help when you need it. Unless you have 30+ hours a week to put in a single class, to run everywhere with questions and expecting incomplete responses, you should probably not take the class. You will most likely have to spend that time to answer your own questions, so just teach yourself from the beginning.
Very good intro to machine learning in general. Keep up with the lectures and you will be fine.
This course is taught very well and requires lots of time on the practicals and homeworks. This is a workload heavy course.
Great way to fill a CS breadth requirement if you're comfortable in probability theory and linear algebra
I really enjoyed this class. We got to explore both the theoretical and practical aspects of machine learning. The class was on the more theoretical/rigorous side, but I enjoyed that. The workload was not too heavy, but I had to manage my workload effectively to handle both the problem sets and practicals. Sometimes the teaching was not very clear and the textbook/course notes did not match up with lecture that well.
CS 181 is really a survey course of various ways in which humans have taught computers to analyze datasets like humans (ex: regression, clustering, neural networks, decision-making). The focus is mostly on the theory, with 1 out of 3 or 4 questions per pset devoted to implementation. Be prepared to do a decent amount of matrix calculus, but you don't really need every single prerequisite in order to take the course (CS 121 followed by Stat 110 are overkill; Linear Algebra is a must). In total, the psets and material are very manageable and the course is definitely worth taking, if not for the utility.
Finale's lectures are generally good, but sometimes she's lecturing a little bit fast and not very clear. You may need to refer to video to get better understanding. Also there's no lecture notes provided, while Finale's writing on board can be really confusing.
Good course to study about machine learning, but be prepared for heavy courseload of homework and practicals.
This was a great class! The topics are very interesting, and Finale did a great job of explaining everything in lecture. The assignments and practicals are time-consuming, but they end up being fun because you get to implement and run cool/powerful algorithms that produce very meaningful results. The class is definitely not easy: a good background in probability theory is essential, and the exams are fairly long regardless. That being said, I definitely still strongly recommend the class!
This class is very well organized and the assessments are very fair. It is a lot more math/proof focused than I had expected but still an interesting class.
This class ends up taking a lot of time when you're tweaking models.
Probably the class I learned the most in during my whole Master's program at Harvard.
Finale did a fantastic job introducing current ideas in the class. While it definitely takes some work to really understand the concepts and do well, it has a definite coolness factor and its applications to real life really makes the work pay off.
It is possible to do decently well in this class without trying very hard, but you won't get much out of it. To be a real data scientist or to effectively applying machine learning algorithms you have to put a lot of effort into understanding the math which can be difficult but worthwhile.
Overall a good course which teaches you quite a bit. Generally the assignments were all quite straightforward.
CS 181 with Prof. Doshi-Velez covered a lot of machine learning algorithms that are widely used in any machine learning settings. It felt like the class sacrificed depth for breadth, but we were still somehow expected to have the depth that was needed to complete the course. I feel that if the course was divided into two semesters and covered more depth for each topics (supervised vs unsupervised learning), then it would be ideal.
It is an intense amount of work, but the lectures are good and the material is important.
Very interesting material. Rigorously taught. Includes practicals alongside psets for both theory and application of the material: in psets you get a few questions of math to work through and then a final question that asks you to implement whatever math you just worked out. In practicals you get a dataset or source of data and have to make something out of it, like whether "swingy monkey" should jump or what songs someone would enjoy or whether a file is a virus or the gap between the highest occupied and lowest unoccupied electron orbital. But despite the coolness of the material there were many problems with this class. Oftentimes I'd feel like I understand what's going on, be stuck in a roadblock, ask someone for help, and their answer would reveal to me I actually never had an idea of what was going on. It's easy to get super lost in this course because of small things you don't understand. I'd suggest doing your homework in office hours and desperately asking questions about everything to make sure you really get it all. I'd also say never miss section. While the sections weren't always that helpful (too much to cover in an hour IMO) they help tremendously with the psets and midterms. I'd also add that Stanford's Machine Learning Course, from the little bit I saw, seemed better, so that's always an option/possibly a helpful tool for this course.
Finale is an excellent instructor. There is a lot of work, but it is structured well. There's so much material in the class, and it moves pretty fast, so be prepared to work a lot. In the end though it's very rewarding.
Good introductory class to Machine Learning which provides a theoretical understanding complemented by applied skills
had a lot of fun with the practicals and kaggle competitions, there was also too much mathy stuff and too broad of an overview of ML, however I guess that would be necessary for a class like this
Be prepared for the heavy workload!!!!!
This is an extremely hard course to evaluate: on the one hand, the topics are very interesting and the lecturer is an excellent teacher, possibly one of the best instructors in the CS faculty when it comes to the delivery of lectures; on the other hand, the lecturer lacks empathy, and when concerns are voiced she gives off an elitist vibe that screams since we are not MIT students we must be idiots. The amount of material covered in this course is astounding. Topics that some courses spend months covering may be dealt with in a single lecture. In the second half of the term, there is about a 7-8 week period where you may have an assignment/homework/exam due almost EVERY WEEK, each of which could well require over 30 hours per week of preparation; if you make any suggestion that this workload is unreasonable, you will simply get a blunt response of "you're all adults, just start early". You will need to be EXTREMELY, EXTREMELY COMFORTABLE with matrix calculus and linear algebra right from the start, otherwise you will feel lost right out of the gates from Day 1, and this feeling may well stay with you until the very end of the semester. You need to also be comfortable programming in Python, and to have used packages such as sci-kit-learn. Be warned, if you don't have this background, you WILL feel lost quickly, and this course may make you cry. There is a reason why the average on the first exam barely broached 60%; while the lectures may be well-delivered, poor overall course organization (and lack of effective remedial support) means that most students who are coming across this material for the first time are being set up for failure.
This is quite a difficult course conceptually and practically. Prepare to spend lots of time on this.
A solid introduction to machine learning; excellent way to gain a lot of intuition around the various techniques/methods.
0) Take this course, not data science. You actually learn how stuff works mathematically. The emphasis on inference and algorithms was refreshing after coming from CS 109 where everything was given a 50,000 foot overview. 1) Don't take this course UNLESS you like probability and statistics! It's not a CS class -- It is a statistical inference course (sometimes very heavy and theoretical), that involves coding for homework. 2) Finale's lectures are crystal clear, she is as good as it gets. Watch lectures. That is where you will learn. The material is hard, though, so don't expect to track with her 100% the first time around. 3) This is just a good course all around. It's definitely work taking. Workload is not light, but it is very manageable. One assignment/test/practical a week. 4) The most challenging aspect of Machine Learning is the notation, but it is very helpful to know going forward.
Great class for getting an overview of the Machine Learning field. Make sure you have enough time to dedicate to the class otherwise you will struggle to get through all the material. Definitely recommend taking this class with friends as it is really helpful for the practicals.
As a graduate student in Biology I think this is a great class for biologists to take, especially those interested in the intersection between Neuroscience and artificial intelligence. But really it's good for anyone who will be doing some kind of data analysis.
Finale is a fair instructor, and mainly teaches at a the level of high-level/abstract concepts. Most of the derivations are tedious / reminiscent of messy stat computations (familiarize yourself with Gaussians..). Sections were mainly just getting answers from the TFs. Overall, the class gave a good broad overview of machine learning, but I felt a little dissatisfied in terms of the depth into which we learned concepts (and with the tedium of the math we had to work through). The textbook wasn't great, and the class didn't have too much structure, especially in the beginning. There was also a little too much variance of ability in the class; sometimes the questions asked in section or on Piazza were frustrating because they seemed to be wasting everyone else's time.
This course gave me a strong introduction to machine learning, both in a high level sense and with regard to the underlying math. You get a broad understanding of the field and its different applications. I found all the material super fascinating and you can clearly see how applicable the material is. It's definitely challenging but not impossible, and it's rewarding as well.
This class covers a good breadth of material and has a fair bit of statistics. Having a good grasp of linear algebra and probability/inference is necessary to get the most out of the class. Even though the practicals were done in groups of three, it is possible to do everything by yourself though it is recommended to do it in groups to enjoy it more. There's the potential to get a lot out of the course but there's also the possibility of taking it and not learning a whole lot if you simply get stuck on the math. Still, the material is super cool and adds a whole new set of tools to your problem solving toolkit so overall its a good choice.
You'll learn a great deal in this course, but in its current form, be prepared to invest a great deal of outside time to make that happen, because to do well grade-wise you'll fare better relying on outside material and explanations. You should judge whether such a course is worth it or not for you. Also, don't take this class without Stat 110. CS109 will help with intuition, but is by no means a prereq.
Prepare for some useless matrix proofs and some incredibly useful techniques and intuition.
This feels like a stats/math course more than a CS course, but it is awesome. This is a very rigorous mathematical approach to machine learning that most other colleges don't give you. The textboox is usually used for graduate-level classes. Be prepared for some difficult math, especially vector and matrix calculus, and some nasty notation. Finale is a very good, clear lecturer.
It is a good course if you put enough effort in.
Do the readings ahead of time to stay on top of lecture material.
A must-take for anyone interested in computer science and relative fields.
This is a math class. Consider yourself warned.
Take this class if you are interested in Machine Learning and you should be. You will have a general idea what ML is and how to apply them. Go ask for helps from TFs, they are really cool, nice and friendly. Make friends with your classmates. I had one of my best group experiences at CS181.
I enjoyed this class, but it's definitely necessary to have a solid math and stat background.
You will need both a strong programming and math background in this class.
CS 181 is a fantastic introduction to machine learning with a focus on understanding the underlying math rather than just coding up existing algorithms.
You learn some interesting things in the class. The assignments however to tend to be quite tedious and not necessarily instructive.
This was my favorite course I took at Harvard. Finale is a fantastic teacher. She skirts the line between complexity and simplicity quite well - she grapples with complex concepts while never going so far that I didn't understand what she was talking about. She always motivates material with a great narrative that helps to relate the material to real world examples.
CS181 was taught by Finale for the first time this year, instead of Adams. Finale was a great professor and I wish I had gotten to know her better. She gave very clear lectures and related the material back to the big picture of machine learning quite well. I learned a lot from the class and really enjoyed it by the end, and it's made me want to study machine learning in further depth. On the other hand, the course was not particularly well structured and course materials were quite lacking. There were no lecture notes to accompany lecture, and section problems weren't always all covered, but we received no solutions. Hopefully this aspect will improve in the future; I still recommend this class, but do understand these caveats!
This class will make you fairly comfortable with a wide variety of tools in machine learning. By not just using pre-built packages but instead looking into the math and theory behind the models and algorithms, you end up understanding them much more fully. 
Only take this class if you're a CS and Stat/applied math JOINT concentrator. If you're CS, the math is too hard. If your math/stat then the coding is too hard. The professor (Finale) is not a good lecturer. She flies through the hard matrix math and it's very difficult to follow. I was a happy person before I took this class. Now happiness is a distant memory.
This is the class to take if you are interested in what machine learning is about! Depending on your background in stat and cs, the course will be of varying difficulty, but worth it for anyone! Finale is a great lecturer and the assignments are also really helpful in solidifying your understanding.
The professor is really amazing. She seemed to genuinely care about the students. However, the class itself is pretty horrible. The lectures are extremely and sometimes unnecessarily mathy and the formulas and derivations in lectures, psets and the exam are honestly not going to prove useful when I want to apply these algorithms in real life. I wish I had taken the MIT version of this class, which is much less mathy and much more applicable.
Challenging but rewarding - definitely great material to learn.
This class has potential to be great, but it's not right now.
Not terribly well organized, the material from class is very different from what the HWs and tests are like. It is the first year Finale is teaching, so it is likely that this will be fixed next time.
Non-trivial course that requires significant amounts of work outside of class.
Overall, a great survey introduction to machine learning. Take this if you want to understand what this hot field has in store. The problem sets could be more interesting, but you'll learn a little of a lot of subjects. You'll come out having a legit understanding, rooted in math, of some of the most popular and useful algorithms. Make sure you have the pre-reqs, or this won't be fun. If you are overprepared, don't get too frustrated (it's probably still worth it to take this class, even though the notation / course staff / materials / problems and practicals get annoying.)
Be wary of the level of mathematical maturity needed
Be prepared for some math-heavy problem sets! Knowledge of basic statistical concepts and basic linear algebra is assumed, but not too difficult to pick up.
Lots of math. Make sure you go to section; that helps a TON
Be sure to be on top of your linear algebra
Great class all-around. The psets are actually quite rewarding, and I walked away understanding the mathematics behind machine learning on a much deeper level. Don't let the notation scare you away! I actually found myself excited to work on the next pset.